{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/ai/7/",
    "result": {"data":{"cur":{"id":"615bf430-e9e7-5473-b80c-2bc74ca70702","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216079662-0d060637-86d4-4577-b486-f1f2d262591d.png\" alt=\"image\"><br></p>\n<p><a href=\"https://tannybrown.github.io/ai/6/\">이전글</a>에서 Gradient Descent에 대해 알아보았다.<br>\r\n이번글에서는 Gradient Descent의 가중치 초기화, Gradient Descent의 <strong>발전된</strong> 버전들에 대해 알아보자.<br></p>\n<br>\n<h2 id=\"1-가중치-초기화\" style=\"position:relative;\"><a href=\"#1-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%B4%88%EA%B8%B0%ED%99%94\" aria-label=\"1 가중치 초기화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 가중치 초기화</h2>\n<p>앞서 배운 Gradient Descent는 초기값을 어떻게 설정하는지에 따라 학습의 속도, 학습의 결과가 바뀌기도 했다.<br>\r\n따라서 초기값을 어떻게 설정하는지는 매우 중요한데, 우리가 해결하고자하는 문제가 무엇인지에 따라 달라진다고 볼 수 있다.<br>\r\n일단 일반적으로 random initialization 방법을 생각할 수 있다. 그외에도 zero initialization, large random initialization 등도 있다.<br>\r\n하지만 이러한 방법들은 너무 단순하다.<br>\r\n이러한 방법 이외에, 현재 가장 많이 쓰이는 3가지 방법이 존재한다.<br></p>\n<ul>\n<li>Xavier(sigmoid / tanh를 사용하는 신경망)<br></li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216111061-e263bbbd-c880-46e4-851e-de826470911d.png\" alt=\"image\"><br>\r\n각 weight가 균등한 분포를 가지도록 설정하는 방법이다. 시그모이드 형태의 활성화 함수와 같은 신경만에서 좋은 결과를 보인다.<br></p>\n<ul>\n<li>Lecun</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216110967-ec9fe53a-1bab-42a6-88bf-dc96207df68f.png\" alt=\"image\"><br></p>\n<ul>\n<li>He(ReLU를 사용하는 신경망)</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216111121-a8e7c732-1e2b-4920-8a3e-23a462aed537.png\" alt=\"image\"><br>\r\nHe initialization은 weight의 값이 적당히 크지만, 너무 작거나 너무 크지 않도록 하여, 신경망의 학습이 잘 되도록 한다.<br>\r\nReLU 활성화 함수와 같은 non-linear 활성화 함수에서, weight의 값이 너무 작으면 뉴런이 “dead”상태가 될 수 있기 때문이다. 반면에, weight의 값이 너무 커지면 학습이 어려워질 수 있다.</p>\n<blockquote>\n<p>지금 단계에서 설명하기엔 다소 어렵기에 전체적인 공부를 마치고 다시 돌아오기로 하자.</p>\n</blockquote>\n<p><br><br></p>\n<h2 id=\"2-stochastic-gradient-descentsgd\" style=\"position:relative;\"><a href=\"#2-stochastic-gradient-descentsgd\" aria-label=\"2 stochastic gradient descentsgd permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Stochastic Gradient Descent(SGD)</h2>\n<p>Gradient Descent는 한계가 존재했다. 신중함과 local minimum.<br>\r\n따라서 새로운 알고리즘들이 나오기 시작했는데, 그중하나가 바로 SGD이다.<br>\r\nSGD는 랜덤하게 하나의 데이터를 뽑아서, 그 데이터만으로 loss를 구해 update를 진행한다.<br></p>\n<blockquote>\n<p>이때 랜덤하게 데이터를 뽑는 과정은 비복원추출을 한다. 또한 데이터를 다 뽑았다면 다시 데이터를 채워서 같은 방식을 반복한다.</p>\n</blockquote>\n<p>따라서, 빠르게 업데이트가 진행된다는 장점이 있다. 또, total gradient와 다른방향으로 이동하기 때문에 local minimum문제에서 탈출할 수도 있다.</p>\n<blockquote>\n<p>‘탈출할 수도 있다.‘이지, 언제나 탈출하는 것은 아니다.</p>\n</blockquote>\n<p>그림으로 확인해보자.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216114527-91d9fc69-db35-4e2c-9413-06d0770bb7fd.png\" alt=\"image\"><br>\r\n위 그림은 loss함수의 contour이다. 즉, 쉽게말해 위에서 본 등고선 정도로 생각하면 된다.<br>\r\n자 여기서 gradient descent는 정확히 minimum을 향해 이동한다. 하지만 SGD는 아주 지 맘대로 이동하는 것을 확인할 수 있다. 이렇게 뽑힌 데이터에 따라 변칙적으로 업데이트가 이루어진다.<br></p>\n<p><br><br></p>\n<h2 id=\"3-mini-batch-sgd\" style=\"position:relative;\"><a href=\"#3-mini-batch-sgd\" aria-label=\"3 mini batch sgd permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. mini-batch SGD</h2>\n<p>SGD는 너무 노이즈(불필요한 움직임이 많음)가 심했다. 따라서 gradient descent와 SGD의 절충안이 필요했는데, 그래서 나온것이 바로, mini-batch SGD이다.<br>\r\nbatch는 업데이트 한번에 필요한 데이터의 수라고 생각하면 좋다. 즉, SGD는 batch의 size가 1인 경우이다.<br>\r\nmini-batch에서도 마찬가지로 비복원 추출을 한다. 그리고 데이터가 batch size 보다 작게 남았으면 남은 수만큼만 다 뽑고 다시 데이터를 채워넣는다. <br>\r\n그렇다면 batch size는 얼마가 적당할까?<br>\r\n일반적으로, GPU가 허락하는 한 최대한 키운다.</p>\n<blockquote>\n<p>아니 너무 키우다가 gradient descent랑 같아지면 어쩌려구요!</p>\n</blockquote>\n<p>괜찮다. 왜냐면 data의 수가 일반적으로 batch size보다 훨씬 많기 때문에 가능한 키우는게 좋다고 한다.<br></p>\n<blockquote>\n<p>추가로, learning rate도 batch-size에 따라 다르게 설정해주어야 성능이 좋다고 한다.</p>\n</blockquote>\n<h3 id=\"용어정리--parameter-vs-hyperparameter\" style=\"position:relative;\"><a href=\"#%EC%9A%A9%EC%96%B4%EC%A0%95%EB%A6%AC--parameter-vs-hyperparameter\" aria-label=\"용어정리  parameter vs hyperparameter permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>용어정리 : parameter vs hyperparameter</h3>\n<p>이쯤에서 용어를 한번 정리하고 가자. <br>\r\n파라미터는 머신이 스스로 알아내는 변수이다. 우리가 앞서 살펴본, weight와 bias가 해당된다.<br>\r\n하이퍼 파라미터는 우리가(인간이) 정해주는 변수를 의미한다. learning rate, batch-size, epoch,model architecture가 해당한다.<br>\r\nEpoch에 대해서는 처음 들어봤을 것이다. epoch는 전체 데이터를 보는 횟수를 의미한다.<br>\r\n예를들어, 총 20개의 데이터가 있고 에포크는 3, 배치 사이즈는 5라고 한다면, 이 모델은 총 12번의 update를 시행한다는 것을 알 수 있다.</p>\n<blockquote>\n<p>모델 아키텍쳐도 처음들어봅니다만?</p>\n</blockquote>\n<p>model architecture는 ‘어떤 모델로 모델링 할것이냐’ 이다. 복잡하게 신경망을 구성해서 모델링을 할 수도 있고, 단순하게 할수도 있을 것이다.<br>\r\n무엇이 좋다라고 말하긴 어렵다. 이또한 문제 상황에 따라 다르며 너무 복잡하게 구성한 경우 오버피팅이 발생할 수 있기에 조심해야 한다.</p>\n<blockquote>\n<p>오버피팅이 뭔데요?</p>\n</blockquote>\n<p>overfitting은 test데이터에 너무나 최적화된 것을 의미하는데, 우리는 새로운 데이터에대한 예측을 하고 싶은 것이기에 이는 적합하지 않다. 이를 방지하기 위해서 regularization, cross validation 등을 이용한다.</p>\n<p><br><br></p>\n<h2 id=\"4-마무리\" style=\"position:relative;\"><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"4 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216293083-e1a0567a-a915-431e-973f-649104747ccc.png\" alt=\"image\"><br></p>\n<p>Gradient Descent의 여러가지 버전에 대해 알아보았다.<br>\r\n<a href=\"https://tannybrown.github.io/ai/8/\">다음글</a>에서는 mini-batch SGD에서 파생된 알고리즘들에 대해 알아보자.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></p>\n</li>\n<li>\n<p><a href=\"#1-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%B4%88%EA%B8%B0%ED%99%94\">1. 가중치 초기화</a></p>\n</li>\n<li>\n<p><a href=\"#2-stochastic-gradient-descentsgd\">2. Stochastic Gradient Descent(SGD)</a></p>\n</li>\n<li>\n<p><a href=\"#3-mini-batch-sgd\">3. mini-batch SGD</a></p>\n<ul>\n<li><a href=\"#%EC%9A%A9%EC%96%B4%EC%A0%95%EB%A6%AC--parameter-vs-hyperparameter\">용어정리 : parameter vs hyperparameter</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\">4. 마무리</a></p>\n</li>\n</ul>\n</div>","excerpt":"0. 지난 이야기 image 이전글에서 Gradient Descent에 대해 알아보았다.\r\n이번글에서는 Gradient Descent의 가중치 초기화, Gradient Descent의 발전된 버전들에 대해 알아보자. 1. 가중치 초기화 앞서 배운 Gradient Descent는 초기값을 어떻게 설정하는지에 따라 학습의 속도, 학습의 결과가 바뀌기도 했다.\r\n따라서 초기값을 어떻게 설정하는지는 매우 중요한데, 우리가 해결하고자하는 문제가 무엇인지에 따라 달라진다고 볼 수 있다.\r\n일단 일반적으로 random initialization 방법을 생각할 수 있다. 그외에도 zero initialization, large random initialization 등도 있다.\r\n하지만 이러한 방법들은 너무 단순하다.\r\n이러한 방법 이외에, 현재 가장 많이 쓰이는 3가지 방법이 존재한다. Xavier(sigmoid / tanh를 사용하는 신경망) image\r\n각 weight가 균등한 분포를 가지…","frontmatter":{"date":"January 30, 2023","title":"6. Gradient Descent 중급편","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/7/"}},"next":{"id":"e9cd9f14-c115-5b0b-a667-0d8058e4739a","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216059096-c5eeb283-5e96-42f6-bd15-7c64ec2b3137.png\" alt=\"image\">\r\n<br>\r\n<a href=\"https://tannybrown.github.io/ai/5/\">이전글</a>에서 선형회귀와 Loss등에 대해 알아보았다. <br>\r\n그리고 우린, 스마트한 방법으로 optimal한 파라미터와 bias를 찾기 위해 Numerical Method를 사용한다는 것까지 알아봤다. <br>\r\n그리고 오늘은 Numerical Method인 Gradient Descent에 대해 알아보자.</p>\n<p><br><br></p>\n<h2 id=\"1-직관적-이해\" style=\"position:relative;\"><a href=\"#1-%EC%A7%81%EA%B4%80%EC%A0%81-%EC%9D%B4%ED%95%B4\" aria-label=\"1 직관적 이해 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 직관적 이해</h2>\n<p>Gradient Descent는 직역하면, 경사하강법이다.<br> 이 방법은 <strong>Loss가 줄어드는 방향</strong>을 찾아 파라미터와 bias를 업데이트 하는 방법이라고 할 수 있다.<br>\r\n예시를 통한 직관적 이해를 해보자.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216073365-d46b5057-690c-4186-b7b8-9727fefb9778.png\" alt=\"image\"><br></p>\n<blockquote>\n<p>그림퀄리티가 상당하다 <br></p>\n</blockquote>\n<p>자, 만약 위 그림에서 최저점을 찾고싶다고 하자. 그리고 현재 우리의 위치가 <strong>파란색 점</strong>으로 주어졌다고 한다면, 우린 어떤 방향으로 나아가야할까?<br>\r\n여러가지 방법론이 있을 수 있지만, <strong>Gradient Descent</strong>에서는 <strong>현재위치에서 기울기의 반대방향</strong> 으로 나아간다.<br>\r\n즉, 기울기가 양수(+)이므로 (-)방향으로 나아가야한다.<br>\r\n자 그럼 어디갈지 알았으니 한발짝 나가아보자. <br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216073715-42b5ea14-97f4-426c-af86-c8782d1b95e6.png\" alt=\"image\">\r\n<br>\r\n엇 이번엔 기울기의 부호가 달라졌다. 현재 기울기의 부호는 (-)이므로 (+)방향으로 가야한다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216074025-07c7dabd-f67f-4f6c-a464-2e824428d45f.png\" alt=\"image\"><br>\r\n드디어 도착했다. 이렇게 기울기가 0이 되면 움직임을 멈추고 최저점을 찾아냈다는 것을 알 수 있다.<br></p>\n<p><br><br>\r\n다소 야매로 그린 예시였지만, 위 그래프가 Loss에 대한 그래프라고 생각한다면, loss가 가장 작아지는 값을 찾고 싶은 우리가 원하는 값에 도달할 수 있었던 것이다.<br>\r\n위 매커니즘을 식으로 표현하면 다음과 같다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216074281-39220e6e-6ced-42ef-bbdf-d43c76437bc3.png\" alt=\"image\"><br>\r\nw는 가중치(파라미터)를 나타내고, L은 Loss function을 의미한다. 입실론은 학습률(learning rate)를 나타내는데, 이는 step-size라고 하기도 한다. 이 step-size에 따라 w를 얼마나 이동시킬지가 달라지며, step-size를 <strong>상수(고정값으로)</strong> 으로 둘 수도 있고 <strong>스케줄링</strong>해서 변하는 값으로 둘 수도 있다.<br></p>\n<blockquote>\n<p>bias는요?</p>\n</blockquote>\n<p>bias도 결국 parameter이다. 즉, 같은 방식인데 bias 에 대해서 같은 과정을 수행하면 된다. 다만 w따로, bias 따로 계산해주는게 귀찮을 수 있다. 따라서 homogeneous equation으로 바꿔서 계산한다면(w의 차원을 하나 올려서) 계산의 편의를 가져갈 수 있다.<br><br></p>\n<h2 id=\"2-한계\" style=\"position:relative;\"><a href=\"#2-%ED%95%9C%EA%B3%84\" aria-label=\"2 한계 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 한계</h2>\n<p>위 글을 따라 오면서 눈치챈 사람이 있을수도 있겠다. Gradient Descent는 명확한 한계를 가진다. <br></p>\n<ul>\n<li>너무 신중하다.</li>\n<li>local minimum <br></li>\n</ul>\n<p>우선 너무 신중하다. 즉 한번의 update를 위해서 갖고 있는 모든 데이터를 이용해 Loss를 계산해야한다. 데이터수가 많아지면 매우매우 느려진다.<br>\r\n두번째로 Local Minimum을 찾는 알고리즘이라는 것이다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216072186-48307436-a632-4a7a-9a5d-7eeaa6b781a5.png\" alt=\"image\"><br></p>\n<p>우리가 알고싶은 것은 global minimum이다. 만약 위와 같은 loss가 주어진다면, 원하는 최저값에 도달하지 못할 수 있다.(<strong>즉, 초기값에 따라 결과가 달라질 것이다</strong>.)<br>\r\n즉, convex한 문제에서만 적용이 가능하다.</p>\n<blockquote>\n<p>알고리즘 공부를 한사람이라면, 눈치챘을 것이다. Gradient Descent는 greedy 하다.</p>\n</blockquote>\n<p><br><br></p>\n<h2 id=\"3-마무리\" style=\"position:relative;\"><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"3 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 마무리</h2>\n<p>이번글에서는 gradient descent에 대해 알아보았다.<br>\r\n<a href=\"https://tannybrown.github.io/ai/7/\">다음글</a>에서는 gradient descent의 보완된 버전들에 대해 알아보자.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></li>\n<li><a href=\"#1-%EC%A7%81%EA%B4%80%EC%A0%81-%EC%9D%B4%ED%95%B4\">1. 직관적 이해</a></li>\n<li><a href=\"#2-%ED%95%9C%EA%B3%84\">2. 한계</a></li>\n<li><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\">3. 마무리</a></li>\n</ul>\n</div>","frontmatter":{"date":"January 29, 2023","title":"5. Gradient Descent 하급편","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/6/"}},"prev":{"id":"25788e54-44ec-55cb-944e-4a91990dddc8","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><a href=\"https://tannybrown.github.io/ai/7/\">이전글</a>에서는 SGD, mini-batch SGD에 대해서 알아보았다.<br>\r\n이번글에서는 mini-batch에서 발전된 알고리즘들을 알아보자.\r\n<br><br></p>\n<h2 id=\"1-momentum-sgd\" style=\"position:relative;\"><a href=\"#1-momentum-sgd\" aria-label=\"1 momentum sgd permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Momentum SGD</h2>\n<p>mini-batch SGD의 단점은 뭐가 있을까? batch사이즈를 키웠다고 하더라도, GD(Gradient Descent)보다 optimal한 값에 ‘정확한’ 방향으로 나아가진 않는다는 점일 것이다.<br>\r\n그림을 통해 확인해보면 다음과 같다.\r\n<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216329482-e6ac4581-3e14-4c80-ac14-a002fec74982.png\" alt=\"image\"><br>\r\n좌우로 너무 많이 흔들리지 않는가? 이러한 단점을 보완하고자 나온것이 Momentum SGD이다. <br>\r\nmomentum SGD을 직관적으로 설명하자면, 관성을 고려하는 update 방법이라고 말할 수 있다. <br>\r\n즉 이전의 gradient들을 고려해서 가중치를 업데이트하는 방법이다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216331203-86f04a3e-1ebc-4b8f-82c0-71aedc3a5a4a.png\" alt=\"image\"><br>\r\n그리고 여기서, optimal 한 값에 거의 도달했을때는 관성(?)때문에 빙글빙글 돌게 된다.<br>\r\n따라서, momentum SGD의 경우 과적합(overfitting)을 방지하고 학습을 개선하는 효과가 있다.</p>\n<h2 id=\"2-rmsprop\" style=\"position:relative;\"><a href=\"#2-rmsprop\" aria-label=\"2 rmsprop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. RMSProp</h2>\n<p>이번엔 또 다른 알고리즘을 살펴보자. <br>\r\nRMSProp(Root Mean Square Propagation)은 지수이동평균(EMA)을 사용하여 각 파라미터의 경사 제곱 값을 계산하여, 경사의 지수이동평균을 적용하여 가중치를 업데이트한다. RMSProp은 <strong>학습률</strong>도 조절하는 기법인데, Gradient의 변화가 큰 파라미터에 대해서는 학습률을 작게 조절하고, Gradient의 변화가 작은 파라미터에 대해서는 학습률을 크게 조절한다. 이를 통해 각 파라미터에 대한 <strong>학습의 안정성</strong>을 높이고, <strong>학습 속도를 개선</strong>할 수 있다.<br>\r\n<br>\r\n잘모르겠다고? 그럴 것 같아서 한번더 정리하면 다음과 같다.<br></p>\n<ol>\n<li>Gradient 계산 : 현재 상태의 파라미터에 대한 Gradient를 계산.</li>\n<li>지수이동평균 계산 : 각 파라미터에 대한 gradient 제곱 값의 EMA를 계산한다.</li>\n<li>학습률 계산 : EMA를 이용해서 각 파라미터에 대한 학습률을 계산한다.</li>\n<li>파라미터 업데이트 : 계산된 학습률을 이용하여 파라미터를 업데이트한다.</li>\n</ol>\n<blockquote>\n<p>초심자의 경우, 이 부분은 넘겨도 좋다. 왜 쓰는지 정도만 이해하도록 하자.</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">예를 들어보자.\r\n현재 파라미터의 값이 [0.8, 1.2, 0.5]이고, 경사 값이 [0.1, -0.3, 0.2]일 때, EMA는 다음과 같이 구할 수 있다.\r\n첫 번째 파라미터(0.8)의 경사 제곱 값: 0.1^2 = 0.01 \r\n두 번째 파라미터(1.2)의 경사 제곱 값: -0.3^2 = 0.09 \r\n세 번째 파라미터(0.5)의 경사 제곱 값: 0.2^2 = 0.04 \r\n\r\n첫 번째 파라미터의 EMA(0.01)은 0.01 * 0.9 + 0.01 * 0.1 = 0.009\r\n두 번째 파라미터의 EMA(0.09)은 0.09 * 0.9 + 0.09 * 0.1 = 0.081\r\n세 번째 파라미터의 EMA(0.04)은 0.04 * 0.9 + 0.02 * 0.1 = 0.038\r\n\r\n학습률은 다음과 같이 계산이 가능하다.\r\n첫 번째 파라미터의 학습률: 0.01 / (0.009 + ε)^0.5 = 0.1\r\n두 번째 파라미터의 학습률: 0.09 / (0.081 + ε)^0.5 = 0.3\r\n세 번째 파라미터의 학습률: 0.02 / (0.038 + ε)^0.5 = 0.2\r\nε는 아주 작은 값으로 수치 안정성을 보장하는 목적으로 사용된다.\r\n\r\n그리고, 이제 학습률을 이용하여 파라미터를 업데이트할 수 있다.\r\n첫 번째 파라미터: 0.8 - 0.1 * 0.1 = 0.79\r\n두 번째 파라미터: 1.2 - 0.3 * 0.3 = 1.11\r\n세 번째 파라미터: 0.5 - 0.2 * 0.2 = 0.48</code></pre></div>\n<br>\r\n<br>\n<h2 id=\"3-adam\" style=\"position:relative;\"><a href=\"#3-adam\" aria-label=\"3 adam permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Adam</h2>\n<p>Adam은 앞서 살펴본 Momentum과 RMSProp의 장점을 합친 알고리즘이다. 따라서 가장 많이 사용되는 알고리즘이라고 볼 수 있다.<br>\r\n즉, moment도 계산하고, 학습률도 변화시켜주는 알고리즘이다.<br>\r\n현 단계에서는 자세한 수식은 접어두고 이정도의 개념만 알아두도록 하자.<br>\r\n<br><br></p>\n<h2 id=\"4-마무리\" style=\"position:relative;\"><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"4 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216343301-4c2a4fcf-3f78-4612-b779-781576e7d801.png\" alt=\"image\"><br></p>\n<p>이번시간엔 mini-batch에서 발전된 3가지 알고리즘에 대해 살펴보았다.<br>\r\n<a href=\"https://tannybrown.github.io/ai/9/\">다음글</a>에서는 Training data와 Test data에 대해 알아보자.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></li>\n<li><a href=\"#1-momentum-sgd\">1. Momentum SGD</a></li>\n<li><a href=\"#2-rmsprop\">2. RMSProp</a></li>\n<li><a href=\"#3-adam\">3. Adam</a></li>\n<li><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\">4. 마무리</a></li>\n</ul>\n</div>","frontmatter":{"date":"February 02, 2023","title":"7. Gradient Descent 고급편","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/8/"}},"site":{"siteMetadata":{"siteUrl":"https://tannybrown.github.io","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/ai/7/","nextSlug":"/ai/6/","prevSlug":"/ai/8/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}