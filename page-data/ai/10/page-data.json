{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/ai/10/",
    "result": {"data":{"cur":{"id":"ad4361ab-0e71-5f15-bf7b-296828c05c55","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><a href=\"https://tannybrown.github.io/ai/9/\">이전글</a>에서 우린 학습에 이용되는 데이터에 대해 다뤄보았다.<br>\r\n이번글에서는 딥러닝에서 뺴놓고 이야기할 수 없는 역전파(Back-Propagation)에 대해 이야기 해보고자 한다!<br></p>\n<p><br><br></p>\n<h2 id=\"1-순전파\" style=\"position:relative;\"><a href=\"#1-%EC%88%9C%EC%A0%84%ED%8C%8C\" aria-label=\"1 순전파 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 순전파</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216831403-ebfd4bd0-5757-487e-9426-f95bd85a83e2.png\" alt=\"image\"> <br></p>\n<p>역전파를 설명하기 전에, 순전파에 대해 먼저 짚고 가야한다. <br>\r\n갑자기 새로운 용어가 나오니 당황스럽겠지만 지금까지 배운 내용에 대한 정리와 다름이 없으니 무리없이 따라올 수 있을 것이다.<br>\r\nDNN을 기억하는가? Deep Neural Network, 깊은 인공신경망을 의미했다.</p>\n<p><br><br></p>\n<h2 id=\"2-역전파\" style=\"position:relative;\"><a href=\"#2-%EC%97%AD%EC%A0%84%ED%8C%8C\" aria-label=\"2 역전파 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 역전파</h2>\n<p><br><br></p>\n<h2 id=\"3-마무리\" style=\"position:relative;\"><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"3 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 마무리</h2>","excerpt":"0. 지난 이야기 이전글에서 우린 학습에 이용되는 데이터에 대해 다뤄보았다.\r\n이번글에서는 딥러닝에서 뺴놓고 이야기할 수 없는 역전파(Back-Propagation)에 대해 이야기 해보고자 한다!  1. 순전파 image  역전파를 설명하기 전에, 순전파에 대해 먼저 짚고 가야한다. \r\n갑자기 새로운 용어가 나오니 당황스럽겠지만 지금까지 배운 내용에 대한 정리와 다름이 없으니 무리없이 따라올 수 있을 것이다.\r\nDNN을 기억하는가? Deep Neural Network, 깊은 인공신경망을 의미했다.  2. 역전파  3. 마무리","frontmatter":{"date":"February 05, 2023","title":"10. 딥러닝의 정수, 역전파","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/10/"}},"next":{"id":"c64cb4d0-2f25-5b30-837f-860f17272f36","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216770908-5015748a-9c27-49df-8bd3-760985b446b0.png\" alt=\"image\"><br></p>\n<p><a href=\"https://tannybrown.github.io/ai/8/\">이전글</a>에서 우리는 mini-batch GD에서 업그레이드 된 RMSProp, Momentum, Adam에 대해 알아보았다.<br>\r\n이번글에서는 머신러닝, 딥러닝에서 사용되는 데이터들을 어떻게 부르는지에 대해 알아보고자 한다.<br></p>\n<p><br><br></p>\n<h2 id=\"1-training-vs-test-vs-validation\" style=\"position:relative;\"><a href=\"#1-training-vs-test-vs-validation\" aria-label=\"1 training vs test vs validation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Training vs Test vs Validation</h2>\n<p>본론으로 들어가기전에, 하나의 예시를 들어보겠다.<br>\r\n아마 이글을 읽는 대대분의 사람은 대입을 준비하는 수험생이었던 적이 있을 것이다.<br>\r\n대입 수험생의 공부는 크게 3가지 파트로 나눌 수 있다.<br></p>\n<ol>\n<li>우리는 수험생 때, 서점에서 문제집을 사서 <strong>문제집</strong>을 푼다.(ex. EBS 수능특강,수능완성 등등)<br></li>\n<li>그리고 6월 9월에 전국 <strong>모의고사</strong>를 본다.<br></li>\n<li>마지막으로 11월 <strong>수능</strong>을 치른다. <br></li>\n</ol>\n<p>볼드체로 표시된 단어를 머신러닝, 딥러닝에 쓰이는 데이터에 mapping시킨다면 다음과 같다.<br></p>\n<ol>\n<li>문제집 -> Training data</li>\n<li>모의고사 -> Validation data</li>\n<li>수능 -> Test data</li>\n</ol>\n<br>\r\n가장 먼저 training data는 모델 학습에 쓰인는 데이터로, 이 데이터를 통해 모델은 학습을 한다.<br>\r\n모델의 학습이 끝났다면, 우리는 test data를 통해서 새로운 데이터가 주어졌을 때 적절한 output을 내는지 확인할 수 있다.<br>\r\n그렇다면 training, test data만 있으면 될 것 같은데 validation data는 왜 필요한 것일까?<br>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216772311-bbb37f2b-16d6-4975-b5e1-d1bf09cb0cc7.png\" alt=\"image\">\r\n<br></p>\n<blockquote>\n<p>여전히 훌륭한 퀄리티의 그림이다.</p>\n</blockquote>\n<p>자 위 그래프를 보면 x축이 총 epoch수, y축이 loss값이다. 우리가 training data로 여러번(많은 epoch) 학습을 수행하면, 점점 loss가 줄어서 거의 오차가 없는 것을 확인할 수 있다.<br>\r\n그렇다면 이렇게 학습을 시키면 test 데이터에 대해서 적절한 결과가 도출될까?<br>\r\n아니다. 이 경우 과적합(overfitting)으로 이어지게 되며, test 데이터에 대해서 성능이 매우 좋지 않게 된다.<br>\r\n따라서 우리는 training 데이터와 새로운 데이터 간의 적절한 절충안을 알아야한다.<br>\r\n이러한 절충안을 알기 위해 나온 것이 바로, validation data이다.<br>\r\ntest data를 통한 test전에, validation data를 통해서 모델의 성능을 평가하여 개발자들은 모델이 실제 새로운 데이터에서 어느 정도의 성능을 보일 것인지에 대한 통찰력을 얻을 수 있다.<br>\r\n오버피팅이 일어나지 않는 적절한 epoch, 성능이 좋은 모델 아키텍쳐 등 <strong>하이퍼 파라미터</strong>를 짐작해보면서 더 좋은 성능의 모델을 만들 수 있는 것이다.<br>\r\n<br><br></p>\n<h2 id=\"2-k-fold-cross-validation\" style=\"position:relative;\"><a href=\"#2-k-fold-cross-validation\" aria-label=\"2 k fold cross validation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. K-fold Cross validation</h2>\n<p>training, test, validation 까지 알아보았다. 그런데 여기서 문제가 하나 발생한다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216772877-2804729f-ee4e-477a-ac25-1e3c439373d8.png\" alt=\"image\"><br>\r\n바로 데이터가 부족하다는 것이다.<br>\r\n데이터만 충분하다면 training, test, validation 데이터를 적절히 나눠서 학습을 진행하면 될 것이다. 허나, 대부분의 경우 우리에게 주어진 데이터는 충분치 못하다.<br>\r\n자 상황을 가정해보자. 우리에게 training data가 100개가 있고 test data가 20개 있다.<br>\r\ntest data는 수능문제니까 건들면 안된다. 그럼 validation data확보를 위해선 training data에 손을 대야한다. 허나 training data도 넉넉치 않은 상황이다.<br>\r\n이때 사용하는 방법 중 하나가 K-fold cross validation이다.<br></p>\n<blockquote>\n<p>k - fold cross validation은 데이터 집합을 k개의 독립적인 폴드로 나누어 k번의 훈련과 평가를 수행하는 것이다. 각 폴드는 훈련 데이터 집합에서 검증 데이터 집합으로 사용되고, k-1개의 폴드는 훈련에 사용된다. k번의 훈련과 평가 과정을 모두 수행한 후, 각 폴드에서의 성능을 평균하여 최종적인 모델의 성능을 평가한다.</p>\n</blockquote>\n<p>지금은 5-fold cross validation을 적용해보자.<br>\r\n100개의 데이터가 있으니, 5개의 fold로 나눈다. 각 폴드는 20개의 데이터로 구성될 것이다. <br>\r\n이제 총 5가지 훈련과 평가 수행한다.</p>\n<blockquote>\n<p>이때 중요한 것이, 아래의 학습은 같은 하이퍼파라미터를 가진 모델이어야 한다.</p>\n</blockquote>\n<ol>\n<li>첫번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>두번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>세번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>네번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>다섯번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n</ol>\n<p>1~5번의 결과를 평균내어, 이러한 하이퍼 파라미터일때의 성능은 이러하다. 라는 결론을 내린다.<br></p>\n<blockquote>\n<p>이렇게 하나의 하이퍼파라미터 세트를 갖고 훈련을 진행하는 것이다.<br> 이 방법을 다른 하이퍼 파라미터 셋에도 적용을 해보고, 서로 다른 하이퍼 파라미터 셋들에 대해서 무엇이 더 성능이 좋은지 확인할 수 있는 것이다.</p>\n</blockquote>\n<br>\n<p>추가로, k-fold cross validation은 데이터 집합의 불균형 해결을 해결할 수 있다.<br>\r\n특정 데이터 포인트나 카테고리가 너무 많이 포함된 경우, 모델의 성능이 떨어질 수 있다. 예를 들어, 강아지 고양이 사진을 분류하는 모델을 만들때, 우리가 설정한 validation data에 강아지 사진만으로 가득하다면, 정확한 validation이 불가할 것이다. 이러한 문제를 k-fold cross validation을 통해서 해결할 수 있는 것이다.<br></p>\n<blockquote>\n<p>또한, overfitting을 방지하는데도 효과가 있다. 특정 데이터가 아닌, 모든 데이터에 대해 학습을 진행하기 때문이다.</p>\n</blockquote>\n<p><br><br></p>\n<h2 id=\"3-마무리\" style=\"position:relative;\"><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"3 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216774441-f6cb1fe0-c28d-42b4-8ae4-3b139e84bd0b.png\" alt=\"image\"><br></p>\n<p>이번글에서는 학습에 쓰이는 데이터들과 k-fold cross validation에 대해 알아보았다.<br>\r\n다음글에서는 역전파에 대해 알아보자.<br></p>","frontmatter":{"date":"February 04, 2023","title":"8. Training Data & Test Data","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/9/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://tannybrown.github.io","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/ai/10/","nextSlug":"/ai/9/","prevSlug":""}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}