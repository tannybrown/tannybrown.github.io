{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/ai/10/",
    "result": {"data":{"cur":{"id":"ad4361ab-0e71-5f15-bf7b-296828c05c55","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><a href=\"https://tannybrown.github.io/ai/9/\">이전글</a>에서 우린 학습에 이용되는 데이터에 대해 다뤄보았다.<br>\r\n이번글에서는 딥러닝에서 뺴놓고 이야기할 수 없는 역전파(Back-Propagation)에 대해 이야기 해보고자 한다.<br></p>\n<p><br><br></p>\n<h2 id=\"1-순전파\" style=\"position:relative;\"><a href=\"#1-%EC%88%9C%EC%A0%84%ED%8C%8C\" aria-label=\"1 순전파 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 순전파</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216831403-ebfd4bd0-5757-487e-9426-f95bd85a83e2.png\" alt=\"image\"> <br></p>\n<p>역전파를 설명하기 전에, 순전파에 대해 먼저 짚고 가야한다. <br>\r\n갑자기 새로운 용어가 나오니 당황스럽겠지만 지금까지 배운 내용에 대한 정리와 다름이 없으니 무리없이 따라올 수 있을 것이다.<br>\r\nDNN을 기억하는가? Deep Neural Network, 깊은 인공신경망을 의미했다. <br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217760131-8cf8bdc2-bbb4-478b-813a-917784e00720.png\" alt=\"image\">\r\n<br>\r\n자 위에 간단한 구조의 인공신경망이 있다. 이때, 입력값으로 x1 = 2, x2 = 1 이 주어지고, f1,f2,f3,f4는 unit step function이라고 해보자.<br>\r\n그렇다면 계산은 다음과 같이 진행될 것이다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217760693-838144b0-195e-4fe2-9305-a252ae410b86.png\" alt=\"image\">\r\n<br>\r\n앞서 배운 바와 같이, 가중치와 입력값을 곱한후 더하여 activation function을 거치는 방식으로 계산하면 Y는 1이 출력된다.<br>\r\n이런식으로 <strong>입력을 통해서 출력값을 구하는 것</strong>을 순전파(Forward-Propagation,Forward-Pass)라고 한다.<br></p>\n<p><br><br></p>\n<h2 id=\"2-역전파\" style=\"position:relative;\"><a href=\"#2-%EC%97%AD%EC%A0%84%ED%8C%8C\" aria-label=\"2 역전파 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 역전파</h2>\n<p>하지만 학습이라는 것은 여기서 끝나는 것이 아니었다.<br>\r\n우리는 이렇게 구한 출력값을 통해서 Loss를 구하고,Loss를 최소로해주는 파라미터로 업데이트를 해줘야한다.<br>\r\n파라미터를 업데이트하는 과정이 바로 back-propagation 인데, 이는 chain rule을 이용해서 계산이 된다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217763519-5c3f81a0-7b59-4368-af62-d3aa2a76577a.png\" alt=\"image\"><br>\r\n아까와 같은 예시에서 확인해보자. 각 노드에 들어가는 입력값을 p라고 하고, 노드에서 나온출력을 q라고 해보겠다.<br>\r\n파라미터 업데이트하는 식을 떠올려보면, Loss function을 w(가중치)로 미분한 Gradient를 구해야했다.<br>\r\n이때 chain rule이 쓰이는데 다음과 같은 형태로 구할 수 있다.<br><br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217765247-9e7aba0c-2735-4971-a4d3-eca0a0b10ee2.png\" alt=\"image\"><br>\r\n이렇게 가장 마지막 층의 가중치를 chain rule을 통해서 update할 수 있다. 이렇게 마지막 층부터 다시 첫번째 층까지 <strong>역순으로 가중치를 업데이트</strong> 한다고 하여 역전파인 것이다.</p>\n<blockquote>\n<p>이렇게만 쓰면 어떻게 알아요!</p>\n</blockquote>\n<p>이제 단순히 미분을 해주면 되는데, p2 = wq1+~라는 관계,q2 = f(p2)라는 관계를 이용하면 쉽게 미분해서 구할 수 있을 것이다.<br>\r\n이제 계산은 당신의 몫이다.<br></p>\n<br>\n<h3 id=\"보충-조금-더-깊은-layer의-weight\" style=\"position:relative;\"><a href=\"#%EB%B3%B4%EC%B6%A9-%EC%A1%B0%EA%B8%88-%EB%8D%94-%EA%B9%8A%EC%9D%80-layer%EC%9D%98-weight\" aria-label=\"보충 조금 더 깊은 layer의 weight permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(보충) 조금 더 깊은 Layer의 weight..</h3>\n<p>그런데 여기서 어렴풋이 알고 넘어가면 틀리는 함정이 하나 숨겨져 있다.<br>\r\n가장 마지막 가중치는 저렇게 구할 수 있었는데, 더 앞쪽 layer의 가중치는 다소 다르다. <br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217772885-fea3b2a6-4996-4b9f-a7be-2ef30201f578.png\" alt=\"image\"><br>\r\n앞선 예시에서 마지막 layer에 노드를 하나 추가했다. 이때, w11을 업데이트 하고 싶다면 어떻게 구할 수 있을까?<br>\r\n아까와 같은 방식으로, chain rule을 이용한다면,<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217772381-ec4f932c-ad68-4212-99ce-1e3bec5a8d8f.png\" alt=\"image\">\r\n<br></p>\n<p>라고 쓸 수 있다. 혹시 이렇게 생각한 분이 있다면 정말 다행이다. 왜냐하면 여기서 추가해줘야하는 식이 더 있기 때문이다.<br>\r\n자 생각해보자. w11이라는 가중치는 p1에 영향을 준다. p1은 q1에 영향을 준다. q1은 p2에, p2는 q2에, q2는 L에 영향을 준다.<br>\r\n이렇게만 영향을 준다면 위 식은 맞다. 하지만 빠진게 있다. q1은 p2뿐아니라 p3에도 영향을 준다. 그리고 p3는 q3에 영향을 주고, q3는 L에 영향을 준다.<br>\r\n즉 w11이라는 가중치를 업데이트하기위해서는 다음과 같은 식으로 Gradient를 구해야할 것이다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217772743-9611e824-a7e7-4cbb-88d9-c0b03e43abc4.png\" alt=\"image\"><br></p>\n<blockquote>\n<p>왜 더하기 입니까?</p>\n</blockquote>\n<p>혹자는 왜 두식을 더하는 것인지 물어볼 수 있다. 이에 대한 자세한 설명은 생략하지만, 미분의 정의를 토대로 생각해보면 덧셈으로 정리되는 식이 도출되니 한번 증명해보는 것도 좋을 것 같다.</p>\n<p><br><br></p>\n<h2 id=\"3-마무리\" style=\"position:relative;\"><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"3 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/217774241-fa17e450-2a13-49b7-b0c6-cf8095743426.png\" alt=\"image\"><br></p>\n<p>이번시간에는 순전파, 역전파에 대해 살펴보았다.<br>\r\n다음글에서는 이진분류로 돌아오겠다.<br></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></p>\n</li>\n<li>\n<p><a href=\"#1-%EC%88%9C%EC%A0%84%ED%8C%8C\">1. 순전파</a></p>\n</li>\n<li>\n<p><a href=\"#2-%EC%97%AD%EC%A0%84%ED%8C%8C\">2. 역전파</a></p>\n<ul>\n<li><a href=\"#%EB%B3%B4%EC%B6%A9-%EC%A1%B0%EA%B8%88-%EB%8D%94-%EA%B9%8A%EC%9D%80-layer%EC%9D%98-weight\">(보충) 조금 더 깊은 Layer의 weight..</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\">3. 마무리</a></p>\n</li>\n</ul>\n</div>","excerpt":"0. 지난 이야기 이전글에서 우린 학습에 이용되는 데이터에 대해 다뤄보았다.\r\n이번글에서는 딥러닝에서 뺴놓고 이야기할 수 없는 역전파(Back-Propagation)에 대해 이야기 해보고자 한다.  1. 순전파 image  역전파를 설명하기 전에, 순전파에 대해 먼저 짚고 가야한다. \r\n갑자기 새로운 용어가 나오니 당황스럽겠지만 지금까지 배운 내용에 대한 정리와 다름이 없으니 무리없이 따라올 수 있을 것이다.\r\nDNN을 기억하는가? Deep Neural Network, 깊은 인공신경망을 의미했다. \r\nimage\r\n\r\n자 위에 간단한 구조의 인공신경망이 있다. 이때, 입력값으로 x1 = 2, x2 = 1 이 주어지고, f1,f2,f3,f4는 unit step function이라고 해보자.\r\n그렇다면 계산은 다음과 같이 진행될 것이다.\r\nimage\r\n\r\n앞서 배운 바와 같이, 가중치와 입력값을 곱한후 더하여 activation function을 거치는 방식으로 계산하면 Y는 1이 출력…","frontmatter":{"date":"February 05, 2023","title":"9. 딥러닝 업데이트 흐름 알기","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/10/"}},"next":{"id":"c64cb4d0-2f25-5b30-837f-860f17272f36","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216770908-5015748a-9c27-49df-8bd3-760985b446b0.png\" alt=\"image\"><br></p>\n<p><a href=\"https://tannybrown.github.io/ai/8/\">이전글</a>에서 우리는 mini-batch GD에서 업그레이드 된 RMSProp, Momentum, Adam에 대해 알아보았다.<br>\r\n이번글에서는 머신러닝, 딥러닝에서 사용되는 데이터들을 어떻게 부르는지에 대해 알아보고자 한다.<br></p>\n<p><br><br></p>\n<h2 id=\"1-training-vs-test-vs-validation\" style=\"position:relative;\"><a href=\"#1-training-vs-test-vs-validation\" aria-label=\"1 training vs test vs validation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Training vs Test vs Validation</h2>\n<p>본론으로 들어가기전에, 하나의 예시를 들어보겠다.<br>\r\n아마 이글을 읽는 대대분의 사람은 대입을 준비하는 수험생이었던 적이 있을 것이다.<br>\r\n대입 수험생의 공부는 크게 3가지 파트로 나눌 수 있다.<br></p>\n<ol>\n<li>우리는 수험생 때, 서점에서 문제집을 사서 <strong>문제집</strong>을 푼다.(ex. EBS 수능특강,수능완성 등등)<br></li>\n<li>그리고 6월 9월에 전국 <strong>모의고사</strong>를 본다.<br></li>\n<li>마지막으로 11월 <strong>수능</strong>을 치른다. <br></li>\n</ol>\n<p>볼드체로 표시된 단어를 머신러닝, 딥러닝에 쓰이는 데이터에 mapping시킨다면 다음과 같다.<br></p>\n<ol>\n<li>문제집 -> Training data</li>\n<li>모의고사 -> Validation data</li>\n<li>수능 -> Test data</li>\n</ol>\n<br>\r\n가장 먼저 training data는 모델 학습에 쓰인는 데이터로, 이 데이터를 통해 모델은 학습을 한다.<br>\r\n모델의 학습이 끝났다면, 우리는 test data를 통해서 새로운 데이터가 주어졌을 때 적절한 output을 내는지 확인할 수 있다.<br>\r\n그렇다면 training, test data만 있으면 될 것 같은데 validation data는 왜 필요한 것일까?<br>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216772311-bbb37f2b-16d6-4975-b5e1-d1bf09cb0cc7.png\" alt=\"image\">\r\n<br></p>\n<blockquote>\n<p>여전히 훌륭한 퀄리티의 그림이다.</p>\n</blockquote>\n<p>자 위 그래프를 보면 x축이 총 epoch수, y축이 loss값이다. 우리가 training data로 여러번(많은 epoch) 학습을 수행하면, 점점 loss가 줄어서 거의 오차가 없는 것을 확인할 수 있다.<br>\r\n그렇다면 이렇게 학습을 시키면 test 데이터에 대해서 적절한 결과가 도출될까?<br>\r\n아니다. 이 경우 과적합(overfitting)으로 이어지게 되며, test 데이터에 대해서 성능이 매우 좋지 않게 된다.<br>\r\n따라서 우리는 training 데이터와 새로운 데이터 간의 적절한 절충안을 알아야한다.<br>\r\n이러한 절충안을 알기 위해 나온 것이 바로, validation data이다.<br>\r\ntest data를 통한 test전에, validation data를 통해서 모델의 성능을 평가하여 개발자들은 모델이 실제 새로운 데이터에서 어느 정도의 성능을 보일 것인지에 대한 통찰력을 얻을 수 있다.<br>\r\n오버피팅이 일어나지 않는 적절한 epoch, 성능이 좋은 모델 아키텍쳐 등 <strong>하이퍼 파라미터</strong>를 짐작해보면서 더 좋은 성능의 모델을 만들 수 있는 것이다.<br>\r\n<br><br></p>\n<h2 id=\"2-k-fold-cross-validation\" style=\"position:relative;\"><a href=\"#2-k-fold-cross-validation\" aria-label=\"2 k fold cross validation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. K-fold Cross validation</h2>\n<p>training, test, validation 까지 알아보았다. 그런데 여기서 문제가 하나 발생한다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/216772877-2804729f-ee4e-477a-ac25-1e3c439373d8.png\" alt=\"image\"><br>\r\n바로 데이터가 부족하다는 것이다.<br>\r\n데이터만 충분하다면 training, test, validation 데이터를 적절히 나눠서 학습을 진행하면 될 것이다. 허나, 대부분의 경우 우리에게 주어진 데이터는 충분치 못하다.<br>\r\n자 상황을 가정해보자. 우리에게 training data가 100개가 있고 test data가 20개 있다.<br>\r\ntest data는 수능문제니까 건들면 안된다. 그럼 validation data확보를 위해선 training data에 손을 대야한다. 허나 training data도 넉넉치 않은 상황이다.<br>\r\n이때 사용하는 방법 중 하나가 K-fold cross validation이다.<br></p>\n<blockquote>\n<p>k - fold cross validation은 데이터 집합을 k개의 독립적인 폴드로 나누어 k번의 훈련과 평가를 수행하는 것이다. 각 폴드는 훈련 데이터 집합에서 검증 데이터 집합으로 사용되고, k-1개의 폴드는 훈련에 사용된다. k번의 훈련과 평가 과정을 모두 수행한 후, 각 폴드에서의 성능을 평균하여 최종적인 모델의 성능을 평가한다.</p>\n</blockquote>\n<p>지금은 5-fold cross validation을 적용해보자.<br>\r\n100개의 데이터가 있으니, 5개의 fold로 나눈다. 각 폴드는 20개의 데이터로 구성될 것이다. <br>\r\n이제 총 5가지 훈련과 평가 수행한다.</p>\n<blockquote>\n<p>이때 중요한 것이, 아래의 학습은 같은 하이퍼파라미터를 가진 모델이어야 한다.</p>\n</blockquote>\n<ol>\n<li>첫번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>두번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>세번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>네번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n<li>다섯번째 폴드를 validation 으로 사용하고, 나머지 4개의 폴드로 훈련을 시킨다.</li>\n</ol>\n<p>1~5번의 결과를 평균내어, 이러한 하이퍼 파라미터일때의 성능은 이러하다. 라는 결론을 내린다.<br></p>\n<blockquote>\n<p>이렇게 하나의 하이퍼파라미터 세트를 갖고 훈련을 진행하는 것이다.<br> 이 방법을 다른 하이퍼 파라미터 셋에도 적용을 해보고, 서로 다른 하이퍼 파라미터 셋들에 대해서 무엇이 더 성능이 좋은지 확인할 수 있는 것이다.</p>\n</blockquote>\n<br>\n<p>추가로, k-fold cross validation은 데이터 집합의 불균형 해결을 해결할 수 있다.<br>\r\n특정 데이터 포인트나 카테고리가 너무 많이 포함된 경우, 모델의 성능이 떨어질 수 있다. 예를 들어, 강아지 고양이 사진을 분류하는 모델을 만들때, 우리가 설정한 validation data에 강아지 사진만으로 가득하다면, 정확한 validation이 불가할 것이다. 이러한 문제를 k-fold cross validation을 통해서 해결할 수 있는 것이다.<br></p>\n<blockquote>\n<p>또한, overfitting을 방지하는데도 효과가 있다. 특정 데이터가 아닌, 모든 데이터에 대해 학습을 진행하기 때문이다.</p>\n</blockquote>\n<p><br><br></p>\n<h2 id=\"3-마무리\" style=\"position:relative;\"><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"3 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/216774441-f6cb1fe0-c28d-42b4-8ae4-3b139e84bd0b.png\" alt=\"image\"><br></p>\n<p>이번글에서는 학습에 쓰이는 데이터들과 k-fold cross validation에 대해 알아보았다.<br>\r\n다음글에서는 역전파에 대해 알아보자.<br></p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></li>\n<li><a href=\"#1-training-vs-test-vs-validation\">1. Training vs Test vs Validation</a></li>\n<li><a href=\"#2-k-fold-cross-validation\">2. K-fold Cross validation</a></li>\n<li><a href=\"#3-%EB%A7%88%EB%AC%B4%EB%A6%AC\">3. 마무리</a></li>\n</ul>\n</div>","frontmatter":{"date":"February 04, 2023","title":"8. Training Data & Test Data","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/9/"}},"prev":{"id":"2a1c0a3a-da22-50e9-a292-8cf98d4d811b","html":"<h2 id=\"0-intro\" style=\"position:relative;\"><a href=\"#0-intro\" aria-label=\"0 intro permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. Intro</h2>\n<p>이들을 아는가?<br></p>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/217831308-836a2764-2411-42c9-8584-76b8acc6813c.png\" alt=\"image\">\r\n<br>\r\n유튜브,넷플릭스,쿠팡<br></p>\n<blockquote>\n<p>??? : 다 아는 얼굴들이구만</p>\n</blockquote>\n<p>다들 한번쯤은 이용해본적이 있는 서비스일 것이다. 우리는 알게 모르게 이러한 서비스들을 이용하면서 추천시스템(Recommender System)을 만나고 있다.\r\n<br>\r\n그럼 추천시스템이라는게 어떤것이고 어떻게 동작하는 것인지 함께 알아가보자.\r\n<br></p>\n<p><br><br></p>\n<h2 id=\"1-추천시스템의-탄생\" style=\"position:relative;\"><a href=\"#1-%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%ED%83%84%EC%83%9D\" aria-label=\"1 추천시스템의 탄생 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 추천시스템의 탄생</h2>\n<p>추천시스템은 <strong>왜</strong> 생겨난걸까?<br>\r\n단순히 추천시스템이 뭔지 받아들이기 전에, 추천시스템은 대체 <strong>왜</strong> 생겨난걸까 생각해보자.<br>\r\n‘정보의 바다’라는 말을 들어본적이 있을 것이다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217833655-22742672-ae3c-459e-a16d-4b3450b0e683.png\" alt=\"image\"><br></p>\n<blockquote>\n<p>나때는 학교에서 인터넷을 설명할때 밀던 키워드였는데 요즘은 또 다르려나</p>\n</blockquote>\n<p>인터넷에서 찾을 수 있는 정보가 매우 많다는 뜻을 비유적으로 표현한 것인데, 이렇게 정보는 많아졌으나 필요한 정보를 찾는데 시간이 매우 오래 걸리게 되었다. (잘못된, 불필요한 정보 또한 많다)<br>\r\n따라서 정보를 찾는데에 시간을 줄여주기 위한 방안을 모색하기 시작하였고 추천시스템이 등장하였다.</p>\n<p><br><br></p>\n<h2 id=\"2-추천시스템recommender-system이란\" style=\"position:relative;\"><a href=\"#2-%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9Crecommender-system%EC%9D%B4%EB%9E%80\" aria-label=\"2 추천시스템recommender system이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 추천시스템(Recommender System)이란?</h2>\n<p><del>추천시스템은 말그대로 추천을 해주는 시스템이다.</del><br></p>\n<blockquote>\n<p>이렇게만 설명하면 너무 야매이므로 중요한 키워드 두가지와 함께 이야기하자.<br></p>\n</blockquote>\n<p>추천시스템은 <strong>User</strong>와 <strong>Item</strong>으로 구성된 시스템이다. 추천시스템은 특정한 유저가 좋아할 아이템을 추천하거나, 비슷한 아이템을 좋아할 유저를 추천한다.<br>\r\n즉, <strong>유저든 아이템이든 관심 갖을만한 정보</strong>를 <strong>추천</strong>하는 것이다.<br>\r\n여기까지만 듣는다면, 검색 서비스와 다를게 없어 보이기도 한다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/217836745-03aa9bae-c14b-4a1b-a860-65c7ad705224.png\" alt=\"image\"><br></p>\n<p>우리는 관심있는 정보를 검색(search)을 통해 얻어내곤 한다. 바로 여기서 추천시스템과의 차이가 생긴다.</p>\n<blockquote>\n<p>검색서비스는 사용자가 스스로 원하는 바를 알고 있다. 즉 사용자가 요구한 정보를 Pull 하는 방식이다. 하지만 추천 시스템은 사용자 스스로 원하는 바를 정확히 알지 못한다. 사용자가 요구하기전에 작동하며 정보를 Push 해준다.</p>\n</blockquote>\n<p><br><br></p>\n<h2 id=\"3-유저와-아이템\" style=\"position:relative;\"><a href=\"#3-%EC%9C%A0%EC%A0%80%EC%99%80-%EC%95%84%EC%9D%B4%ED%85%9C\" aria-label=\"3 유저와 아이템 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 유저와 아이템</h2>\n<p>추천시스템이 해야할 가장 큰 역할은 바로 유저와 아이템간의 관계를 분석하여 연관관계를 찾는 것이다.\r\n추천시스템은 연관관계를 점수화하여 어떠한 사용자, 어떠한 아이템을 좋아하게 될지 판단하여 추천을 진행한다.\r\n이때 유저의 정보와 아이템의 정보를 이용한다.<br>\r\n유저의 정보로는, <strong>고유정보</strong>(나이,성별 등)과 <strong>로그</strong>(행동패턴)이 있고 아이템의 정보로는 아이템의 <strong>고유정보</strong>(가격,색상 등)이 있다.\r\n<br><br></p>\n<p>자 그러면 이러한 정보들을 프로파일링 해야한다.<br>\r\n추천시스템에서는 <strong>유저 프로필</strong>과 <strong>아이템 프로필</strong>을 만든다.<br>\r\n먼저 유저 프로필은 앞서 나온 정보들 외에도 사용자 정보를 수집하기 위한 방법(설문조사, 평가, 피드백)등을 이용한다.\r\n이를 통해 개인별 추천이나 사용자 그룹별 추천이 가능하여 유저 프로필을 만드는 것은 매우 중요한 과정이다.<br>\r\n아이템 프로필은 플랫폼마다 정의하는 아이템의 <strong>종류</strong>가 다르다. <br>\r\n따라서 플랫폼마다 관련있는 아이템만을 추천하게 되는데, 일반적으로 아이템의 고유정보, 아이템을 좋아하거나 구매한 사용자 정보등을 이용하여 아이템 프로필을 구성할 수 있다.</p>\n<p><br><br></p>\n<h2 id=\"4-추천점수\" style=\"position:relative;\"><a href=\"#4-%EC%B6%94%EC%B2%9C%EC%A0%90%EC%88%98\" aria-label=\"4 추천점수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 추천점수</h2>\n<p>유저와 아이템 분석이 끝났다면 이를 바탕으로 추천 점수를 계산한다.<br>\r\n유저 또는 아이템 프로필에서 어떤 정보를 사용할지에 따라서 추천알고리즘을 결정한다.<br></p>\n<blockquote>\n<p>즉 유저 프로필과 아이템 프로필을 feature 삼아 알고리즘을 적용하는 것이다.</p>\n</blockquote>\n<p>추천 알고리즘은 <strong>점수화</strong>를 위한 것으로 사용자 또는 아이템을 점수매겨 <strong>top-N(상위 n개)을 추천</strong>한다.<br>\r\n<br><br></p>\n<h2 id=\"5-마무리\" style=\"position:relative;\"><a href=\"#5-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"5 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/217842132-1c4ab2e7-1093-4ca2-b1ff-ec63f192c1ca.png\" alt=\"image\">\r\n<br>\r\n이번 글에서는 추천시스템이 무엇인지, 추천시스템을 이루는 요소등에 대해 알아보았다.<br>\r\n<a href=\"https://tannybrown.github.io/recommend_system/2/\">다음글</a>에서는 아이템 또는 사용자를 점수화하는 추천알고리즘에 대해서 알아보자.<br></p>\n<br>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#0-intro\">0. Intro</a></li>\n<li><a href=\"#1-%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%ED%83%84%EC%83%9D\">1. 추천시스템의 탄생</a></li>\n<li><a href=\"#2-%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9Crecommender-system%EC%9D%B4%EB%9E%80\">2. 추천시스템(Recommender System)이란?</a></li>\n<li><a href=\"#3-%EC%9C%A0%EC%A0%80%EC%99%80-%EC%95%84%EC%9D%B4%ED%85%9C\">3. 유저와 아이템</a></li>\n<li><a href=\"#4-%EC%B6%94%EC%B2%9C%EC%A0%90%EC%88%98\">4. 추천점수</a></li>\n<li><a href=\"#5-%EB%A7%88%EB%AC%B4%EB%A6%AC\">5. 마무리</a></li>\n</ul>\n</div>","frontmatter":{"date":"February 09, 2023","title":"0. 추천시스템 알아보기","categories":"추천시스템","author":"tanny","emoji":"🔮"},"fields":{"slug":"/recommend_system/1/"}},"site":{"siteMetadata":{"siteUrl":"https://tannybrown.github.io","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/ai/10/","nextSlug":"/ai/9/","prevSlug":"/recommend_system/1/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}