{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/ai/12/",
    "result": {"data":{"cur":{"id":"e1401dd9-31c3-56be-98e7-824572e6fb3f","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/218152623-d8e0c8c0-7dd6-4c25-870f-feafbde86a87.png\" alt=\"image\"><br></p>\n<p><a href=\"https://tannybrown.github.io/ai/11/\">이전글</a>에서는 non-linear activation을 쓰는 이유에 대해 살펴보았다. <br>\r\n이번글에서는 <strong>이진분류</strong>에 대해서 살펴보며, <strong>sigmoid</strong>를 쓰는 이유를 알아보도록 하자. <br></p>\n<br>\r\n<br>\n<h2 id=\"1-이진분류-문제with-unit-step-function\" style=\"position:relative;\"><a href=\"#1-%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98-%EB%AC%B8%EC%A0%9Cwith-unit-step-function\" aria-label=\"1 이진분류 문제with unit step function permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 이진분류 문제(with unit step function)</h2>\n<p>이전까지 회귀문제를 살펴보았고, 이번엔 분류(classification)를 살펴보려고 한다.<br>\r\n가장 간단한 분류인 이진분류를 먼저 알아보자.<br>\r\n이진분류는 말그대로 ‘둘 중 하나로 분류하는 것’을 의미한다. 예를 들면, 어떠한 사진을 보고, 개냐 고양이냐와 같은 문제 말이다.<br>\r\n하나의 예시를 같이 보면서 이진분류를 하나 생각해보겠다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218140868-140e287d-9a09-4ebf-9a75-cf54a1b1aa59.png\" alt=\"image\"><br></p>\n<blockquote>\n<p>정말 그래프 퀄리티가 엄청나다.</p>\n</blockquote>\n<p><strong>키</strong>와 <strong>몸무게</strong>에 따른 분포가 주어진 그래프가 있다. 이 그래프에서 살을 찌워야하는 사람(저체중)과 살을 빼야하는 사람(과체중)을 분류하려한다.<br>\r\n이때 단순하게 한개의 layer 만을 이용해서 분류해보자. 또, 활성화 함수로는 non-linear activation인 unit step function을 이용해보자.</p>\n<blockquote>\n<p>unit step function은 0보다 크면 1, 0보다 작으면 0을 출력하는 함수로, 0또는 1을 출력하므로 이진분류를 할 수 있다.</p>\n</blockquote>\n<p>퍼셉트론을 구성해서 다음과 같이 학습을 잘 마쳤다고 해보자.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218144577-7c56d787-24d2-49f6-8060-17e96dc72de7.png\" alt=\"image\"><br>\r\nx를 키,y를 몸무게 라고 한다면, y = x + 1 직선이 그래프상에서 분류의 기준선이 됨을 알 수 있다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218144994-472f6afc-1c1b-4975-8b10-c5eef714dffe.png\" alt=\"image\"><br>\r\n이렇게 키와 몸무게라는 feature를 갖고 이진분류를 할 수 있었다.<br></p>\n<br>\r\n<br>\n<h2 id=\"2-unit-step-function의-문제점\" style=\"position:relative;\"><a href=\"#2-unit-step-function%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90\" aria-label=\"2 unit step function의 문제점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. unit step function의 문제점</h2>\n<p>앞서 이진분류를 해보았는데, 문제가 있다.<br></p>\n<blockquote>\n<p>??? : 문제를 삼으면 문제가 되고 문제를 삼지 않으면 문제가 되지 않…</p>\n</blockquote>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/218145633-df7314e7-eb9f-41fd-a14a-0c2e2682036b.png\" alt=\"image\"><br>\r\n파랑색 데이터가 주어졌을때, 이 데이터는 분류기상에서 과체중으로 분류된다.<br>\r\n허나 실제로 이 데이터는 과체중은 아니다. 정확히 말하면 평균체중, 정상체중이라고 볼 수 있다.<br>\r\n이렇게 unit step function은 1 또는 0으로만 표현하기때문에 ‘정도’를 표현할 수가 없다.<br>\r\n따라서 ‘정도’를 표현하기 위해서 우린 다른 activation을 써볼 것이다. 바로, sigmoid!</p>\n<blockquote>\n<p>unit step function의 단점은 이뿐만이 아니다. <br>\r\nstep function이기에 미분도 불가능하다. 즉 gradient descent를 쓸 수 없다.<br>\r\n또, 분류를 뭣같이한다. 오버피팅이라고 봐야할까? 선을 막그어도 분류가 되기만 하면 ok이다. 정도 표현이 안되니 아슬아슬하게 분류하기도 한다는 말!</p>\n</blockquote>\n<br>\r\n<br>\n<h2 id=\"3-이진분류-문제with-sigmoid\" style=\"position:relative;\"><a href=\"#3-%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98-%EB%AC%B8%EC%A0%9Cwith-sigmoid\" aria-label=\"3 이진분류 문제with sigmoid permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 이진분류 문제(with Sigmoid)</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/218146967-db2d4cab-dfe5-4519-bb09-8a1a443e0ee0.png\" alt=\"image\"><br><br>\r\n위 함수를 sigmoid 함수라고 한다. 식을 보고 바로 느껴야하는 것이 바로, <strong>전구간 미분가능</strong>하다는 것이다. <br>\r\n자그러면 sigmoid 함수개형을 그려보자.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218147185-eee489d1-b8e8-41af-a345-8b457c24c2f4.png\" alt=\"image\"><br>\r\n딱 보기에도, unit step function보다 유연함을 알 수 있다.<br>\r\nsigmoid를 이용하여 위 분류문제를 풀 경우 다음과 같은 결과를 얻어낼 수 있다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218148024-892e1bee-2835-4ab1-8518-50e261aae7c7.png\" alt=\"image\"><br></p>\n<blockquote>\n<p>그림판을 이용하다보니.. 죄송합니다.</p>\n</blockquote>\n<p>보면 알 수 있듯, 유연하게 분류되는 곡면을 갖게 된다. 이게 뭐가 좋은것이냐? <br>\r\n파란점을 분류할때 sigmoid는 0에서 1사이의 숫자를 출력할 것이다. 지금 그래프를 참고해서 0.52정도를 출력했다고 해보자.<br>\r\n0에 가까우면 저체중, 1에 가까우면 과체중으로 판별이 가능하니, 0.52라는 수치는 굳이 살을 뺄필요도, 찌울필요도 없다는 것으로 판단할 수 있다.</p>\n<blockquote>\n<p>이처럼 0과1사이의 수치로 출력된 결과를 통해서 ’<strong>정도</strong>‘를 판단할 수 있게 된다.(정도를 ‘확률’로 해석하기도 한다.)</p>\n</blockquote>\n<p>sigmoid의 장점은 이뿐만이 아니다.<br>\r\nsigmoid는 <strong>합리적인 기준선</strong>을 찾는다.</p>\n<blockquote>\n<p>이게 무슨말이에요?</p>\n</blockquote>\n<p>unit step function처럼 <strong>무지성 분류</strong>가 아니라는 말이다. sigmoid는 두 class를 구분짓는, <strong>가장 멀리 찢어놓는 선</strong>을 찾는다.<br>\r\n예를 들어<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218150681-3da98d2e-de0b-436a-8300-b6cf82b1efae.png\" alt=\"image\"><br>\r\n이렇게 분류해도 unit step function은 분류를 한것이다.(즉 학습을 멈춘다.)<br>\r\n하지만 sigmoid는 아니다. sigmoid는 더 최적의 weight를 찾아서 학습을 계속한다. 따라서 더 적절한 분류기준선을 찾는다.</p>\n<br>\n<p>정리하면</p>\n<ul>\n<li>미분가능</li>\n<li>부드러운 분류</li>\n<li>확률로 해석가능</li>\n<li>합리적인 분류 기준선</li>\n</ul>\n<p>이 가능하다.\r\n<br>\r\n<br></p>\n<h2 id=\"4-마무리\" style=\"position:relative;\"><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"4 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/218152336-640eb4a9-ebf7-4ada-bda6-924a6f0f9e6a.png\" alt=\"image\"><br></p>\n<p>이번 시간에는 이진분류가 무엇인지, sigmoid를 왜써야하는지 알아보았다.<br>\r\n<a href=\"https://tannybrown.github.io/ai/13/\">다음글</a>에서는 이진분류와 likelihood에 대해 알아보도록 하겠다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></li>\n<li><a href=\"#1-%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98-%EB%AC%B8%EC%A0%9Cwith-unit-step-function\">1. 이진분류 문제(with unit step function)</a></li>\n<li><a href=\"#2-unit-step-function%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90\">2. unit step function의 문제점</a></li>\n<li><a href=\"#3-%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98-%EB%AC%B8%EC%A0%9Cwith-sigmoid\">3. 이진분류 문제(with Sigmoid)</a></li>\n<li><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\">4. 마무리</a></li>\n</ul>\n</div>","excerpt":"0. 지난 이야기 image 이전글에서는 non-linear activation을 쓰는 이유에 대해 살펴보았다. \r\n이번글에서는 이진분류에 대해서 살펴보며, sigmoid를 쓰는 이유를 알아보도록 하자.  1. 이진분류 문제(with unit step function) 이전까지 회귀문제를 살펴보았고, 이번엔 분류(classification)를 살펴보려고 한다.\r\n가장 간단한 분류인 이진분류를 먼저 알아보자.\r\n이진분류는 말그대로 ‘둘 중 하나로 분류하는 것’을 의미한다. 예를 들면, 어떠한 사진을 보고, 개냐 고양이냐와 같은 문제 말이다.\r\n하나의 예시를 같이 보면서 이진분류를 하나 생각해보겠다.\r\nimage 정말 그래프 퀄리티가 엄청나다. 키와 몸무게에 따른 분포가 주어진 그래프가 있다. 이 그래프에서 살을 찌워야하는 사람(저체중)과 살을 빼야하는 사람(과체중)을 분류하려한다.\r\n이때 단순하게 한개의 layer 만을 이용해서 분류해보자. 또, 활성화 함수로는 non-linear …","frontmatter":{"date":"February 11, 2023","title":"11. 이진분류 (상)편 (feat.sigmoid를 쓰는 이유)","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/12/"}},"next":{"id":"c8797234-97fb-56fa-b34d-79f035505ba5","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><a href=\"https://tannybrown.github.io/ai/10/\">이전글</a>에서는 역전파에 대해 알아보았다.<br>\r\n이번글에서는 non-linear activation은 왜 쓰는 것인지! 알아보겠다.<br></p>\n<br>\r\n<br>\n<h2 id=\"1-linear-activation\" style=\"position:relative;\"><a href=\"#1-linear-activation\" aria-label=\"1 linear activation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Linear activation</h2>\n<p>앞선 글들을 잘 읽어왔다면, activation function 이 무엇인지는 알고 있을 것이다.<br></p>\n<blockquote>\n<p>모르는 사람들을 위해서.<br>\r\n활성화 함수를 의미하며, 인공신경망 구조에서 <strong>입력신호의 총합을 출력신호로 바꿔주는 함수</strong>를 의미한다.<br>\r\n인체의 뉴런속의 시냅스와 유사한 역할이다.</p>\n</blockquote>\n<p>그러면 linear activation은 무엇인가?<br>\r\nlinear activation은 활성화 함수가 linear function인 경우, 즉 1차 함수 형태인 경우를 의미한다.<br></p>\n<blockquote>\n<p>예를들어, activation function으로 f(x) = x 를 쓰는 경우를 들 수 있다.<br>\r\n이 경우, 입력으로 받은 값이 그대로 출력으로 나올 것이다.</p>\n</blockquote>\n<p>linear activation은 딥러닝에서 많이 사용되는 활성화 함수이다. 대표적으로 회귀문제, 마지막 계층의 활성화 함수, LSTM or GRUs등의 순환 신경망에서 사용된다.<br></p>\n<br>\r\n<br>\n<h2 id=\"2-linear-activation의-한계\" style=\"position:relative;\"><a href=\"#2-linear-activation%EC%9D%98-%ED%95%9C%EA%B3%84\" aria-label=\"2 linear activation의 한계 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Linear activation의 한계</h2>\n<p>linear activation은 입출력의 크기를 변하지 않게 하는 장점이 있지만, 단점 또한 존재한다.<br>\r\n이번글에서 전달하고 싶은 linear activation의 단점은 바로, linear activation만으로는 <strong>복잡한 인공신경망</strong>을 표현하지 못한다는 것이다.<br></p>\n<h3 id=\"복잡한-인공신경망\" style=\"position:relative;\"><a href=\"#%EB%B3%B5%EC%9E%A1%ED%95%9C-%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D\" aria-label=\"복잡한 인공신경망 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>복잡한 인공신경망?</h3>\n<p>그저 layer가 깊으면 복잡한 인공신경망일까? 약 100층, 200층, 1000층을 쌓으면 복잡한 인공신경망일까?<br>\r\n복잡한 인공신경망이기 위해서는 한가지 조건이 필요하다. 바로 activation function이 linear activation이 아니어야 한다는 것이다.<br>\r\n왜 그런것인지 예시를 통해 살펴보자.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218087901-2fd4007f-8b1e-4962-988b-a7015ed234a4.png\" alt=\"image\"><br>\r\n가장 기본적인 구조로 1차함수 wx + b 를 만들어 보았다. 여기까지는 쉽게 따라 올 수 있을 것이다.<br>\r\n그렇다면 여기서 더 층(layer)를 늘려본다면 더 복잡한 출력을 가질 수 있을지 살펴보자.\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218087373-3e4a1db2-37db-430b-a6c0-bd0fc5469a6d.png\" alt=\"image\"><br>\r\n조금 더 층을 늘려서 표현해보았다.<br>\r\n출력을 보면 f(f(x)w + b)의 형태인데 f(x)가 linear activation 이므로 이결과 역시 linear function이 된다.<br>\r\n즉슨, 층을 아무리 늘려도 g(x) = aw + b 의 형태를 벗어나지 못한다는 뜻이다.</p>\n<blockquote>\n<p>결론 : linear activation으로는 아무리 깊게 만들어도 hidden layer 없는 인공신경망 만큼의 표현력만 갖게 된다.</p>\n</blockquote>\n<br>\r\n<br>\n<h2 id=\"3-non-linear-activation\" style=\"position:relative;\"><a href=\"#3-non-linear-activation\" aria-label=\"3 non linear activation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Non-linear activation</h2>\n<p>이러한 linear activation의 한계가 있기때문에, 우리는 non-linear activation을 같이 사용한다.<br>\r\n대표적인 non-linear activation으로는 unit step fuction, sigmoid 등이 있다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218089610-0e3216e4-efc6-40dc-8620-b331da1ee99b.png\" alt=\"image\">\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218089725-0858eb69-5ea0-405f-af66-e86907006c1b.png\" alt=\"image\"><br></p>\n<p>unit step function은 우리가 일전에 봤으니 설명은 생략하고 sigmoid는 다음글에서 다룰 예정이다.</p>\n<br>\n<blockquote>\n<p>그렇다고 linear activation이 꼭 안좋고 나쁜것만은 아니다.\r\nTrade-Off는 언제나 존재한다.<br>\r\n일반적으로 복잡한 작업에는 non-linear activation이 선호되는 반면, 입력과 출력 사이의 선형 관계를 원하는 간단한 회귀 문제에는 linear activation이 유용하다.</p>\n</blockquote>\n<br>\r\n<br>\n<h2 id=\"4-마무리\" style=\"position:relative;\"><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"4 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 마무리</h2>\n<p>이번글에서는 non-linear activation을 써야하는 이유에 대해 알아보았다.<br>\r\n<a href=\"https://tannybrown.github.io/ai/12/\">다음글</a>에서는 이진분류에 대해 알아보도록 하자.\r\n<br>\r\n<br></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></p>\n</li>\n<li>\n<p><a href=\"#1-linear-activation\">1. Linear activation</a></p>\n</li>\n<li>\n<p><a href=\"#2-linear-activation%EC%9D%98-%ED%95%9C%EA%B3%84\">2. Linear activation의 한계</a></p>\n<ul>\n<li><a href=\"#%EB%B3%B5%EC%9E%A1%ED%95%9C-%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D\">복잡한 인공신경망?</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#3-non-linear-activation\">3. Non-linear activation</a></p>\n</li>\n<li>\n<p><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\">4. 마무리</a></p>\n</li>\n</ul>\n</div>","frontmatter":{"date":"February 10, 2023","title":"10. non-linear activation은 왜 쓰는 것일까?","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/11/"}},"prev":{"id":"a173e29d-6b8c-5e9d-8959-d8526baf3383","html":"<h2 id=\"0-지난-이야기\" style=\"position:relative;\"><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"0 지난 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>0. 지난 이야기</h2>\n<p><a href=\"https://tannybrown.github.io/ai/12/\">이전글</a>에서 이진분류가 무엇인지, sigmoid를 왜쓰는지 알아봤다.<br>\r\n이번글에서는 sigmoid를 이용한 이진분류에 대해서 좀더 깊숙히 알아가보자.</p>\n<br>\r\n<br>\n<h2 id=\"1-이진분류\" style=\"position:relative;\"><a href=\"#1-%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98\" aria-label=\"1 이진분류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 이진분류</h2>\n<p>이번에도 예를 들며 이야기를 풀어나가보겠다.<br>\r\n뻔한 예시지만, 강아지 사진과 고양이 사진을 input으로 주고 두 사진을 분류하는 이진분류 모델을 만든다고 생각해보자.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218488865-2bed71cb-0aa5-445f-bba7-d0803fe22610.png\" alt=\"image\"><br>\r\n사진데이터 이므로 RGB 3개의 필터에 대한 데이터가 들어올것이다. 각각 필터에 대한 픽셀사이즈가 100 * 100이라고 한다면, 데이터 하나당 30000짜리 벡터가 들어온다고 보면 된다.<br>\r\n그렇다면 단순하게 hidden layer가 1개라고 해도 이런 인공신경망이 그려질 것이다.<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218490908-d7c7a35d-8a7f-40e7-b76d-922c888e3da1.png\" alt=\"image\"><br>\r\n그러면 30001개의 가중치를 각각 모두 미분하면서 업데이트를 진행해야할 것이다.</p>\n<blockquote>\n<p>30001개인 이유는 30000(가중치들) + 1(bias)</p>\n</blockquote>\n<br>\r\n<br>\n<h2 id=\"2-loss-정의하기-1\" style=\"position:relative;\"><a href=\"#2-loss-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0-1\" aria-label=\"2 loss 정의하기 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Loss 정의하기 1</h2>\n<p>그러면 Loss를 w로 미분하면서 업데이트 할것이니, Loss를 정하자.<br>\r\n우리는 이전까지 보통 Loss로 MSE(mean square error)를 써왔다. 하지만 이진분류 문제에서는 MSE말고 다른 Loss를 이용한다.<br></p>\n<blockquote>\n<p>왜 MSE를 안쓰나요?<br>\r\n간략하게 설명하면, MSE가 값의 절대값을 고려하지 않아(제곱하니까), 값의 범위가 0과 1 사이인 확률에 대한 근사값을 반환하며, 클래스의 경계를 잘 표현하지 않을 수 있기 때문이다.</p>\n</blockquote>\n<p>그럼 뭘쓰냐?<br>\r\n우선, 몇가지 정의를 하자. 강아지 사진을 1, 고양이 사진을 0이라고 정의하자. (0또는 1로 출력하는 이진분류니까 ㅇㅇ) 이 <strong>정답</strong> 값을 p라고 하자.</p>\n<blockquote>\n<p>p가 0이면 고양이, p가 1이면 강아지 인것이다.<br></p>\n</blockquote>\n<p>그리고 머신의 입력은 사진데이터였고, <strong>출력</strong>(<strong>예측값</strong>)은 <strong>강아지 사진일 확률</strong>이라고 정의해보자. 그 확률 값을 q라고 하겠다.<br></p>\n<blockquote>\n<p>여기까지 괜찮죠? 예측은 q, 정답은 p, 강아지는 1, 고양이는 0, q는 강아지일 확률 ㅇㅋ?<br></p>\n</blockquote>\n<p>자 이제 만약 강아지 사진이 입력으로 들어왔다고 생각해보자. 그렇다면 우리는 출력을 뭘해야하는가?<br>\r\n그렇다. 1을 출력해야한다. 맞죠?<br>\r\n그런데 이 1을 출력해야한다는 말을 조금 다르게 표현해보겠다.<br>\r\n’<strong>q의 값을 최대화 해야한다.</strong>’ 라고.<br>\r\n그럼 반대로 고양이 사진일때는? ’<strong>q를 최소화 해야한다.</strong>’<br></p>\n<blockquote>\n<p>??? : 이해가 안갑니다.<br>\r\nq는 <strong>시그모이드의 출력값</strong>이니 <strong>0과 1사이의 값</strong>이 나올 것입니다. 따라서 q의 값을 최대화한다. -> q가 1이 나오게 만든다. 라고 해석할 수 있다.</p>\n</blockquote>\n<p>자 그런데, 강아지일때는 최대화, 고양이 일때는 최소화 하려고 하니까, 방향성이 일관되었으면 좋겠다.<br>\r\n우린 현재 강아지기준으로 생각을 하고 있으니, 고양이일때 최소화를 최대화라는 표현으로 바꿔보려 한다.<br>\r\n따라서 고양이일때 q대신 -q를 쓴다면, ’<strong>-q를 최대화 해야한다.</strong>’ 라고 해석할 수 있다.<br>\r\n여기까지 간단한데 생각해보면, -q라는 값은 범위가 -1 ~ 0이다. 우리는 q의 출력과 동일하게 해주고 싶으니까 1 - q라고 정의해버리면, 범위는 0~1로 만들 수 있다.<br></p>\n<blockquote>\n<p>결론 : 고양이 사진일때, ‘q를 최소화해야한다’ -> ’<strong>1-q를 최대화해야한다.</strong>’</p>\n</blockquote>\n<p>여기까지 왔다면, 이제 강아지와 고양이 케이스를 하나의 식으로 표현해보자.<br>\r\n앞서 우리가 정의한 p와 q를 이용해 하나의 식으로 표현할 수 있을 것이다.<br></p>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/218497596-0f15ca23-ab02-4a14-b2b5-8f813be7d6d1.png\" alt=\"image\"><br>\r\n아주 멋있는 식이다. 강아지 사진이면 p = 1일테니 괄호항은 1이 되고 q가 만들어진다.(강아지 사진일 확률!)<br>\r\n고양이 사진이면 p = 0일테니 좌항이 털리고, 1 - q가 만들어진다.(고양이 사진일 확률!)<br>\r\n자그러면, 위 식을 최대화하면 우리가 원하는 <strong>출력</strong>을 만들 수 있다라는 것을 알게 되었다.<br>\r\n위 식은 가만 생각하면, 입력값에 따른 확률이다. 따라서 우리는 아래 첨자를 써서 첫번째 입력에 대한 확률을 <img src=\"https://user-images.githubusercontent.com/121401159/218500335-962f4e53-772a-48b6-b55e-4fe67ac94997.png\" alt=\"image\">\r\n<br>\r\n라고 표현할 수 있다.<br>\r\n사진은 하나만 들어오지 않는다. 따라서 각 사진들 별로 확률을 구해줘야하는데, 이때 각각의 사진들에 대한 확률은 독립시행임을 알 수 있다.<br>\r\n독립시행이니 각각의 확률을 곱해주면 된다. 즉,<br>\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218502953-18c099a4-6330-4021-b787-eccbb13fac40.png\" alt=\"image\">\r\n<br>\r\n을 최대화 하면 된다.라는 결론에 다다른다.<br></p>\n<blockquote>\n<p>자 그런데 여기까지 왔다면 한가지 의문이 든다. 확률은 0과 1사이의 값이니, 그 값들을 계속 곱해나간다면 0에 수렴하지 않나…?</p>\n</blockquote>\n<p>맞다. 1에 가까운 0.9라는 값만 해도 100승을 취하면 0에 가까운 수가 되어버린다.</p>\n<blockquote>\n<p>0 에 가까운 수는 문제가 있나요?\r\n문제가 있다. 컴퓨터는 이진수로 수를 처리하다보니, 소수를 표현하는데에 한계가 있다. 따라서 너무 깊은 소수에서는 정확도가 떨어진다.</p>\n</blockquote>\n<br>\r\n<br>\n<h2 id=\"3-loss-정의하기-2\" style=\"position:relative;\"><a href=\"#3-loss-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0-2\" aria-label=\"3 loss 정의하기 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Loss 정의하기 2</h2>\n<p>이러한 문제를 해결하기 위해 공학자들이 취한 방법은 ‘로그’ 이다.<br></p>\n<blockquote>\n<p>왜? <strong>곱</strong>이 <strong>합</strong>이 되니까.<br>\r\n또 가능한 이유중 하나가, log함수 역시 단조 증가함수이기 때문이다. 증감이 변하지 않으니 상당히 유용한 기법이다.</p>\n</blockquote>\n<p>즉 log를 취한 값을 최대화 한다. 로 바뀌게 된다.<br>\r\n그래서 정리하면,\r\n<img src=\"https://user-images.githubusercontent.com/121401159/218508564-c1941e29-0e9a-4c65-82ec-476e8488e0f0.png\" alt=\"image\"><br>\r\n로 정의된다. (-가 붙었으니 최소화의 의미)</p>\n<blockquote>\n<p>라이클리후드가 뭡니까?<br>\r\nlikelihood는 설명하기 참 어려운 개념이다. 간단히만 말하자면, P(분포|확률변수)를 확률변수의 함수로 보는것을 likelihood라 한다.</p>\n</blockquote>\n<p>이렇게 loss 까지 정의하면. 학습만 시키면 된다. 끝이라고 볼 수 있다.<br>\r\n이를 logistic regression이라고 한다.<br>\r\n로지스틱 회귀는 이름에 붙은 regression이라는 이름이 무색하게, 회귀문제에 쓰이는게 아니라 분류 문제를 해결하는 알고리즘이다.<br></p>\n<blockquote>\n<p>닉값을 못한다.</p>\n</blockquote>\n<p>다소 장황한 해설이 이어졌는데, 이부분은 정말 어려운 부분이고 수학적인 개념이 많이 등장하는 부분이라 필자도 다시 또 공부하면서 더 좋은 보충 설명을 할 수 있도록 노력이 필요할 것 같다.<br></p>\n<br>\r\n<br>\n<h2 id=\"4-마무리\" style=\"position:relative;\"><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"4 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 마무리</h2>\n<p><img src=\"https://user-images.githubusercontent.com/121401159/218512409-f48899f7-6cea-4082-834f-69b2aced889b.png\" alt=\"image\">\r\n<br>\r\n이번 글은 너무 어려웠다. 사실 더 설명하고 싶은 내용들도 있으나, 추후에 따로 작성되는 글을 통해서 <strong>why</strong>에 대한 이야기들을 더 풀어가 보고자 한다.<br>\r\n다음글에서는 다중분류로 찾아오겠다. 그럼 안녕</p>\n<br>\r\n<br>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#0-%EC%A7%80%EB%82%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0\">0. 지난 이야기</a></li>\n<li><a href=\"#1-%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98\">1. 이진분류</a></li>\n<li><a href=\"#2-loss-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0-1\">2. Loss 정의하기 1</a></li>\n<li><a href=\"#3-loss-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0-2\">3. Loss 정의하기 2</a></li>\n<li><a href=\"#4-%EB%A7%88%EB%AC%B4%EB%A6%AC\">4. 마무리</a></li>\n</ul>\n</div>","frontmatter":{"date":"February 11, 2023","title":"12. 이진분류 (하)편 (feat.log-likelihood)","categories":"AI/ML/DL","author":"tanny","emoji":"🔮"},"fields":{"slug":"/ai/13/"}},"site":{"siteMetadata":{"siteUrl":"https://tannybrown.github.io","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/ai/12/","nextSlug":"/ai/11/","prevSlug":"/ai/13/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}