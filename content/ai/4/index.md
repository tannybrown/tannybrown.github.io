---
emoji: 🔮
title: 3. 딥러닝의 시작, 인공신경망
date: '2023-01-28 02:00:00'
author: tanny
tags: 
categories: AI/ML/DL
---

## 0. 신경세포 뉴런
[이전글](https://tannybrown.github.io/ai/3/)에서 머신러닝의 분야에 대해 살펴보았다. <br>
이번글에서는 딥러닝의 기초가 되는 인공신경망에 대해 다뤄보도록 하자.<br>
<br>
당신이 고등학교 생명과학 시간에 졸지 않았다면 이 그림을 기억할 것이다.<br><br>
![image](https://user-images.githubusercontent.com/121401159/215143541-5dff4459-54d7-4dbb-bdd5-fd6bb3b4e511.png)<br>
<br>
위 그림은 신경세포 **뉴런**을 나타낸 것으로, 가지돌기에서 여러 자극을 전달받고, 핵에서 자극을 전달할지를 결정하며, 축삭돌기를 통해 또 다른 신경세포로 자극이 전달된다.<br>
딥러닝에서 사용되는 **인공신경망**은 이름에서 알수 있듯, 이 신경세포의 동작방식과 닮아 있다. <br><br><br>


## 1. 퍼셉트론
우리의 신체에 뉴런이 있듯, 딥러닝의 인공신경망에는 **퍼셉트론**이 있다.
![image](https://user-images.githubusercontent.com/121401159/215151104-d731ca4b-ca65-4651-bb82-1e82b4ca5ed6.png)<br>
위 그림은 퍼셉트론을 나타낸 것인데 한번 살펴보자.<br>
우선 좌측의 x 값들은 퍼센트론의 **input**에 해당한다. 위 예시에서는 두개만 그렸지만 여러개의 **input**이 있을 수 있다.<br>
그리고 x와 연결된 선에 써있는 w를 우린 **가중치** 혹은 **파라미터** 라고 부른다. 이 파라미터는 각각의 input들과 곱해진다.<br>
그리고 가장 아래 있는 **bias**는 **편향, 민감도**를 나타내며 따로 가중치가 곱해지지 않는다. <br>
퍼셉트론은 이렇게 들어온 인풋과 파라미터를 곱한 값을 더하고 바이어스까지 더해준다. 수식으로 표현하면 다음과 같다.<br><br>
![image](https://user-images.githubusercontent.com/121401159/215153563-403ed017-a9f1-4444-bf4c-27836bcefbb0.png)<br>
<br>
이렇게 계산하면 끝이냐? 아니다. 이렇게 계산한 결과를 **활성화 함수(activation function)** 에 넣어준다.<br>
이때 활성화 함수로는 **unit step function**(입력이 0보다 작으면 0, 1보다 크면 1을 출력)을 사용한다.<br>
> 자 이제 슬슬 궁금한게 있을 것이다. 하나씩 대답해주겠다.

**??? : 바이어스는 왜 있어야하나요?**<br>
바이어스가 없다면, input으로 0이 들어왔을때 언제나 출력값이 0이 된다. 즉슨, 인풋이 0일때 우리가 원하는 결과를 맞춰주기 위해 필요하다. <br><br>
**??? : 활성화 함수는 unit step function만 쓰나요?** <br>
퍼셉트론에서는 unit step function을 사용한다. 하지만 MLP(Multi-Layer perceptron)등 다른 모델에서는 여러가지 다양한 활성화 함수를 사용한다. <br>

> 추가적으로, 퍼셉트론의 선을 edge라고 부르고, activation 함수가 있는 동그라미를 node라고 부른다. 알아두자.



<br><br>

## 2. 다층 퍼셉트론(MLP)
앞서 살펴본 퍼셉트론을 **'단층 퍼셉트론'** 이라고 부른다. <br>
말그대로 층이 하나였기 때문에 붙여진 이름인데, 우린 이러한 단층 퍼셉트론을 여러겹으로 쌓을 수 있다. 그렇게 여러층의 퍼셉트론으로 구성한 것을 '**다층 퍼셉트론**'이라고 부른다.<br>
![image](https://user-images.githubusercontent.com/121401159/215158159-dd434850-9cc3-4436-b371-1809b1133dea.png)<br>

몇가지 용어를 더 살펴보면, 입력을 받는 부분을 **입력층**, 출력하는 부분을 **출력층** 이라고 하며, 중간에 있는 layer를 **은닉층(hidden layer)** 라고 한다. 그리고 모든 노드에 엣지가 연결되어 있으면 **fully connected** 라고 부른다. <br>
마지막으로, 은닉층이 2개 이상인 신경망을 우린 **DNN(Deep Neural Network)** 이라고 한다.
> DNN? 어디서 들어봤는데?

라는 생각이 들었다면 정말 고맙다. 맞다. 첫번째 글에서 살펴보았던, 딥러닝에 사용된다고 소개했던 것이 바로 DNN이다.<br>

<br><br>

## 3. 그래서 이걸 어떻게 써먹어요?
지금까지 잘 따라왔다면 이런 의문이 든다. <br>
> 퍼셉트론, 다층 퍼셉트론... 일단 뭔진 알겠는데 이거 가지고 뭐 어떻게 머신러닝, 딥러닝을 한다는거야?

**학습**에 대해 설명하면 이 궁금증은 해결된다. <br>
머신러닝, 딥러닝에서 말하는 **학습**이라는 것이 바로, 위에서 살펴본 **가중치**와 **bias**를 업데이트하며 **최적의 가중치와 bias**를 찾는 과정이다. <br>
뭔소린지 모르겠다고?

![image](https://user-images.githubusercontent.com/121401159/215161222-9a6ad1d3-df29-4f6b-9be0-3127625a06ce.png)<br>

다음글에서 이에대한 궁금증을 해결해보자.
