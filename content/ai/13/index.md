---
emoji: 🔮
title: 12. 이진분류 (하)편 (feat.log-likelihood)
date: '2023-02-11 00:00:01'
author: tanny
tags: 
categories: AI/ML/DL
---

## 0. 지난 이야기
[이전글](https://tannybrown.github.io/ai/12/)에서 이진분류가 무엇인지, sigmoid를 왜쓰는지 알아봤다.<br>
이번글에서는 sigmoid를 이용한 이진분류에 대해서 좀더 깊숙히 알아가보자.


<br>
<br>

## 1. 이진분류
이번에도 예를 들며 이야기를 풀어나가보겠다.<br>
뻔한 예시지만, 강아지 사진과 고양이 사진을 input으로 주고 두 사진을 분류하는 이진분류 모델을 만든다고 생각해보자.<br>
![image](https://user-images.githubusercontent.com/121401159/218488865-2bed71cb-0aa5-445f-bba7-d0803fe22610.png)<br>
사진데이터 이므로 RGB 3개의 필터에 대한 데이터가 들어올것이다. 각각 필터에 대한 픽셀사이즈가 100 * 100이라고 한다면, 데이터 하나당 30000짜리 벡터가 들어온다고 보면 된다.<br>
그렇다면 단순하게 hidden layer가 1개라고 해도 이런 인공신경망이 그려질 것이다.<br>
![image](https://user-images.githubusercontent.com/121401159/218490908-d7c7a35d-8a7f-40e7-b76d-922c888e3da1.png)<br>
그러면 30001개의 가중치를 각각 모두 미분하면서 업데이트를 진행해야할 것이다.
> 30001개인 이유는 30000(가중치들) + 1(bias)
<br>
<br>

## 2. Loss 정의하기 1
그러면 Loss를 w로 미분하면서 업데이트 할것이니, Loss를 정하자.<br>
우리는 이전까지 보통 Loss로 MSE(mean square error)를 써왔다. 하지만 이진분류 문제에서는 MSE말고 다른 Loss를 이용한다.<br>
> 왜 MSE를 안쓰나요?<br>
> 간략하게 설명하면, MSE가 값의 절대값을 고려하지 않아(제곱하니까), 값의 범위가 0과 1 사이인 확률에 대한 근사값을 반환하며, 클래스의 경계를 잘 표현하지 않을 수 있기 때문이다.

그럼 뭘쓰냐?<br>
우선, 몇가지 정의를 하자. 강아지 사진을 1, 고양이 사진을 0이라고 정의하자. (0또는 1로 출력하는 이진분류니까 ㅇㅇ) 이 **정답** 값을 p라고 하자.
> p가 0이면 고양이, p가 1이면 강아지 인것이다.<br>

그리고 머신의 입력은 사진데이터였고, **출력**(**예측값**)은 **강아지 사진일 확률**이라고 정의해보자. 그 확률 값을 q라고 하겠다.<br>
> 여기까지 괜찮죠? 예측은 q, 정답은 p, 강아지는 1, 고양이는 0, q는 강아지일 확률 ㅇㅋ?<br>

자 이제 만약 강아지 사진이 입력으로 들어왔다고 생각해보자. 그렇다면 우리는 출력을 뭘해야하는가?<br>
그렇다. 1을 출력해야한다. 맞죠?<br>
그런데 이 1을 출력해야한다는 말을 조금 다르게 표현해보겠다.<br>
'**q의 값을 최대화 해야한다.**' 라고.<br>
그럼 반대로 고양이 사진일때는? '**q를 최소화 해야한다.**'<br>
> ??? : 이해가 안갑니다.<br>
> q는 **시그모이드의 출력값**이니 **0과 1사이의 값**이 나올 것입니다. 따라서 q의 값을 최대화한다. -> q가 1이 나오게 만든다. 라고 해석할 수 있다.

자 그런데, 강아지일때는 최대화, 고양이 일때는 최소화 하려고 하니까, 방향성이 일관되었으면 좋겠다.<br>
우린 현재 강아지기준으로 생각을 하고 있으니, 고양이일때 최소화를 최대화라는 표현으로 바꿔보려 한다.<br>
따라서 고양이일때 q대신 -q를 쓴다면, '**-q를 최대화 해야한다.**' 라고 해석할 수 있다.<br>
여기까지 간단한데 생각해보면, -q라는 값은 범위가 -1 ~ 0이다. 우리는 q의 출력과 동일하게 해주고 싶으니까 1 - q라고 정의해버리면, 범위는 0~1로 만들 수 있다.<br>
> 결론 : 고양이 사진일때, 'q를 최소화해야한다' -> '**1-q를 최대화해야한다.**'

여기까지 왔다면, 이제 강아지와 고양이 케이스를 하나의 식으로 표현해보자.<br>
앞서 우리가 정의한 p와 q를 이용해 하나의 식으로 표현할 수 있을 것이다.<br>

![image](https://user-images.githubusercontent.com/121401159/218497596-0f15ca23-ab02-4a14-b2b5-8f813be7d6d1.png)<br>
아주 멋있는 식이다. 강아지 사진이면 p = 1일테니 괄호항은 1이 되고 q가 만들어진다.(강아지 사진일 확률!)<br>
고양이 사진이면 p = 0일테니 좌항이 털리고, 1 - q가 만들어진다.(고양이 사진일 확률!)<br>
자그러면, 위 식을 최대화하면 우리가 원하는 **출력**을 만들 수 있다라는 것을 알게 되었다.<br>
위 식은 가만 생각하면, 입력값에 따른 확률이다. 따라서 우리는 아래 첨자를 써서 첫번째 입력에 대한 확률을 ![image](https://user-images.githubusercontent.com/121401159/218500335-962f4e53-772a-48b6-b55e-4fe67ac94997.png)
<br>
라고 표현할 수 있다.<br>
사진은 하나만 들어오지 않는다. 따라서 각 사진들 별로 확률을 구해줘야하는데, 이때 각각의 사진들에 대한 확률은 독립시행임을 알 수 있다.<br>
독립시행이니 각각의 확률을 곱해주면 된다. 즉,<br>
![image](https://user-images.githubusercontent.com/121401159/218502953-18c099a4-6330-4021-b787-eccbb13fac40.png)
<br>
을 최대화 하면 된다.라는 결론에 다다른다.<br>
> 자 그런데 여기까지 왔다면 한가지 의문이 든다. 확률은 0과 1사이의 값이니, 그 값들을 계속 곱해나간다면 0에 수렴하지 않나...?

맞다. 1에 가까운 0.9라는 값만 해도 100승을 취하면 0에 가까운 수가 되어버린다. 
> 0 에 가까운 수는 문제가 있나요?
> 문제가 있다. 컴퓨터는 이진수로 수를 처리하다보니, 소수를 표현하는데에 한계가 있다. 따라서 너무 깊은 소수에서는 정확도가 떨어진다. 
<br>
<br>

## 3. Loss 정의하기 2
이러한 문제를 해결하기 위해 공학자들이 취한 방법은 '로그' 이다.<br>
> 왜? **곱**이 **합**이 되니까.<br>
> 또 가능한 이유중 하나가, log함수 역시 단조 증가함수이기 때문이다. 증감이 변하지 않으니 상당히 유용한 기법이다.

즉 log를 취한 값을 최대화 한다. 로 바뀌게 된다.<br>
그래서 정리하면, 
![image](https://user-images.githubusercontent.com/121401159/218508564-c1941e29-0e9a-4c65-82ec-476e8488e0f0.png)<br>
로 정의된다. (-가 붙었으니 최소화의 의미)
> 라이클리후드가 뭡니까?<br>
> likelihood는 설명하기 참 어려운 개념이다. 간단히만 말하자면, P(분포|확률변수)를 확률변수의 함수로 보는것을 likelihood라 한다.

이렇게 loss 까지 정의하면. 학습만 시키면 된다. 끝이라고 볼 수 있다.<br>
이를 logistic regression이라고 한다.<br>
로지스틱 회귀는 이름에 붙은 regression이라는 이름이 무색하게, 회귀문제에 쓰이는게 아니라 분류 문제를 해결하는 알고리즘이다.<br>
> 닉값을 못한다.

다소 장황한 해설이 이어졌는데, 이부분은 정말 어려운 부분이고 수학적인 개념이 많이 등장하는 부분이라 필자도 다시 또 공부하면서 더 좋은 보충 설명을 할 수 있도록 노력이 필요할 것 같다.<br>

<br>
<br>

## 4. 마무리
![image](https://user-images.githubusercontent.com/121401159/218512409-f48899f7-6cea-4082-834f-69b2aced889b.png)
<br>
이번 글은 너무 어려웠다. 사실 더 설명하고 싶은 내용들도 있으나, 추후에 따로 작성되는 글을 통해서 **why**에 대한 이야기들을 더 풀어가 보고자 한다.<br>
다음글에서는 다중분류로 찾아오겠다. 그럼 안녕











<br>
<br>

```toc
```
